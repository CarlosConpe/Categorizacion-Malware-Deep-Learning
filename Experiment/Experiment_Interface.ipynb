{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nTkSrr9uQ46Y",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We create an abstract machine learning class. Every machine learning model we use will inherit from this. We can observe that it has no real functionality as-is besides for giving us an idea of the interface. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "k-UbT5AXP6hT",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Abstract class for machine learning models. We will use this to inherit to specific models and override each method when inherited.\n",
    "class machine_learning_model:\n",
    "  #CONSTRUCTOR: Currently does nothing besides storing the name we gave it\n",
    "  def __init__(self, * ,model_name, verbose):\n",
    "    self.name = model_name\n",
    "    self.verbose = verbose\n",
    "\n",
    "  #Method for compiling our machine learning model\n",
    "  def compile(self):\n",
    "    if self.verbose:\n",
    "      print(\"Model Compiled!\")\n",
    "\n",
    "  #Method to process our data such that it is usable by our model\n",
    "  def parse_data(self, dataset):\n",
    "    self.processed_dataset = []\n",
    "    #We choose to store the processed data in our model. This might have to change later depending on RAM consumption for this process...\n",
    "    if self.verbose:\n",
    "      print(\"Data Processed!\")\n",
    "\n",
    "  #Method for training our machine learning model. It will use the processed dataset\n",
    "  def train(self):\n",
    "    if self.verbose:\n",
    "      print(\"Model Trained!\")\n",
    "    self.training_time = 1000\n",
    "\n",
    "  #Method for evaluating our machine learning model. We use this to compute how accurate it is\n",
    "  def evaluate(self, samples):\n",
    "    for sample in samples:\n",
    "      print(sample)\n",
    "    self.precision = 0.9\n",
    "    self.loss = 0.1\n",
    "    if self.verbose:\n",
    "      print(\"Model Accuracy:\", self.precision)\n",
    "    self.mean_evaluation_time = 10\n",
    "\n",
    "  #Method to run the entire model. This is interface that would be used for any model. \n",
    "  def run_model(self, dataset, samples):\n",
    "    self.compile()\n",
    "    self.parse_data(dataset)\n",
    "    self.train()\n",
    "    self.evaluate(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine - Experiment model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ! libraries that are required for this implementation\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# * This implements support vector machine classification and regression.\n",
    "class SupportVectorMachine(machine_learning_model):\n",
    "\n",
    "    \"\"\"\n",
    "    Build classifier\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    regularization: Regularization parameter. The strength of the regularization is inversely \n",
    "    proportional to C. Must be strictly positive.\n",
    "    kernel: Specifies the kernel type to be used in the algorithm.\n",
    "    degree: Degree of the polynomial kernel function (poly). Ignored by all other kernels.\n",
    "    gamma{scale, auto} : Kernel coefficient for rbf, poly and sigmoid.\n",
    "\n",
    "    \"\"\"\n",
    "    # Constructor\n",
    "    def __init__(self, regularization=1.0, kernel='rbf', degree=3, gamma='scale', name=\"Support Vector Machine\", verbose=\"True\"):\n",
    "        super(SupportVectorMachine, self).__init__(model_name = name, verbose = verbose)\n",
    "        self.regularization = regularization\n",
    "        self.kernel = kernel\n",
    "        self.degree = degree\n",
    "        self.gamma = gamma\n",
    "\n",
    "    # Method to build the support vector machine model\n",
    "    def build(self):\n",
    "        self.clf = SVC(C=self.regularization, kernel=self.kernel, degree=self.degree, gamma=self.gamma)\n",
    "\n",
    "    # Method for compiling\n",
    "    def compile(self):\n",
    "        try:\n",
    "            self.build()\n",
    "            if self.verbose:\n",
    "                print(\"Model Compiled!\")\n",
    "        except:\n",
    "            print(\"Model wasn't compiled correctly!\")\n",
    "\n",
    "    # Method to process our data such that it is usable by our model\n",
    "    def parse_data(self, dataset):\n",
    "        super().parse_data()\n",
    "\n",
    "    \"\"\"\n",
    "    Fit the SVM model according to the given training data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    training_data : {array-like, sparse matrix} of shape (n_samples, n_features) or (n_samples, n_samples)\n",
    "        Training vectors, where `n_samples` is the number of samples and `n_features` is the number of features.\n",
    "    training_labels : array-like of shape (n_samples,)\n",
    "        Target values (class labels in classification).\n",
    "    sample_weight : array-like of shape (n_samples,), default=None\n",
    "        Per-sample weights. Rescale C per sample. Higher weights\n",
    "        force the classifier to put more emphasis on these points.\n",
    "    \"\"\"\n",
    "    def train(self, training_data, training_labels, sample_weight=None):\n",
    "        try:\n",
    "            fitted_estimator = self.clf.fit(X = training_data, y = training_labels,sample_weight=sample_weight)\n",
    "            if self.verbose:\n",
    "                print(\"Model Trained!\")\n",
    "                self.training_time = 1000 # ! NEED UPDATE\n",
    "        except:\n",
    "            print(\"Model wasn't trained correctly!\")\n",
    "            self.training_time = -1\n",
    "\n",
    "    \"\"\"\n",
    "    Perform regression on samples in X.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    samples : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
    "    \"\"\"\n",
    "    def evaluate(self, samples):\n",
    "        try:\n",
    "            sample_predictions = self.clf.predict(samples)\n",
    "            self.precision = accuracy_score(samples, sample_predictions) \n",
    "            self.loss = 100.0 - self.precision\n",
    "            if self.verbose:\n",
    "                print(\"Model Accuracy:\", self.precision)\n",
    "            self.mean_evaluation_time = 10 # ! NEED UPDATE\n",
    "        except:\n",
    "            print(\"Model Accuracy: -1\")\n",
    "            self.precision = -1\n",
    "            self.loss = -1\n",
    "\n",
    "    #Method to run the entire model. This is interface that would be used for any model. \n",
    "    def run_model(self, dataset, samples):\n",
    "        self.compile()\n",
    "        self.parse_data(dataset)\n",
    "        self.train()\n",
    "        self.evaluate(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFcSn1V4NKAk",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We create an experiment class. We will create an experiment which will be in charge of evaluating our different AI models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "iHfTFCVkNHdk",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#This class will be used to run instances of our experiment. We can run as many experiments as we would like\n",
    "class experiment:\n",
    "  #Helper function for constructor(Used to print the name of our models)\n",
    "  def print_model_ids(self):\n",
    "    for model in self.array_of_models:\n",
    "      print(\"   -\", model.name)\n",
    "\n",
    "  #CONSTRUCTOR: We store the dataset and models we will use for the experiment\n",
    "  def __init__(self, *, array_of_models, raw_dataset):\n",
    "    self.array_of_models = array_of_models\n",
    "    self.raw_dataset = raw_dataset\n",
    "    print(\"=========================================\")\n",
    "    print(\"Experiment Configured. We will test the following models: \")\n",
    "    print(\"=========================================\")\n",
    "    self.print_model_ids()\n",
    "\n",
    "  #We prepare our models by compiling them\n",
    "  def prepare_models(self):\n",
    "    if self.verbose:\n",
    "      print(\"=========================================\")\n",
    "      print(\"Compiling our models\")\n",
    "      print(\"=========================================\")\n",
    "      for model in self.array_of_models:\n",
    "        print(\"Compiling\", model.name)\n",
    "        model.compile()\n",
    "      print(\"\")\n",
    "\n",
    "  #We train our models with the dataset\n",
    "  def train_models(self):\n",
    "    if self.verbose:\n",
    "      print(\"=========================================\")\n",
    "      print(\"Training our models\")\n",
    "      print(\"=========================================\")\n",
    "      for model in self.array_of_models:\n",
    "        print(\"Training\", model.name)\n",
    "      print(\"\")\n",
    "    for model in self.array_of_models:\n",
    "      model.train()\n",
    "  \n",
    "  #We evaluate the precision of our models\n",
    "  def evaluate_models(self, our_samples):\n",
    "    if self.verbose:\n",
    "      print(\"=========================================\")\n",
    "      print(\"Evaluating our models\")\n",
    "      print(\"=========================================\")\n",
    "      for model in self.array_of_models:\n",
    "        print(\"Evaluating\", model.name)\n",
    "      print(\"\")\n",
    "    for model in self.array_of_models:\n",
    "      model.evaluate(our_samples)\n",
    "\n",
    "  #Method to sort our arrays by accuracy!!!!\n",
    "  def sort_models(self):\n",
    "    array_sorted_by_precision = sorted(self.array_of_models, key = lambda model: model.precision, reverse = True)\n",
    "    return array_sorted_by_precision\n",
    "\n",
    "  #We print the results of the experiment. We are sorting based on accuracy of the model when evaluating.\n",
    "  #Supported sorting metrics: training time, evaluation time, accuracy, loss.\n",
    "  #To implement: memory consumption, complexity of model, more?\n",
    "  def print_model_statistics(self):\n",
    "    print(\"Experiment Results:\")\n",
    "    print(\"=========================================\")\n",
    "    best_models = self.sort_models()\n",
    "    print(\"Models sorted by accuracy: \")\n",
    "    for model in best_models:\n",
    "      print(model.name, \":\", model.precision * 100, \"%.\")\n",
    "    print(\"=========================================\")\n",
    "  \n",
    "  #Method to generate samples for accuracy testing. We randomly select samples from our dataset\n",
    "  def generate_samples(self):\n",
    "    our_samples = []\n",
    "    return our_samples\n",
    "\n",
    "  #ACTUAL EXPERIMENT CALL: In this method we are running our experiment.\n",
    "  def begin_experiment(self, *,  training_epochs, training_proportion, verbose):\n",
    "    self.verbose = verbose\n",
    "    #=========================================================================================\n",
    "    #Troubleshooter:\n",
    "    if self.verbose:\n",
    "      if len(self.array_of_models) == 0:\n",
    "        print(\"Error! No models available for testing\")\n",
    "      for i in range(0, len(self.array_of_models)):\n",
    "        if type(self.array_of_models[i]) != machine_learning_model:\n",
    "          print(\"Error! Untestable data has been selected\")\n",
    "          return\n",
    "      training_epochs = int(training_epochs)\n",
    "      if training_epochs < 1:\n",
    "        print(\"Error! Epochs cannot be less than 1\")\n",
    "        return\n",
    "      if training_epochs < 3:\n",
    "        print(\"Warning: Epochs should be at least 3\")\n",
    "\n",
    "      if training_proportion > 1 and training_proportion <= 100:\n",
    "        print(\"Warning: Training proportion should be expressed as a decimal from 0 to 1\")\n",
    "        training_proportion = training_proportion / 100\n",
    "      \n",
    "      if training_proportion <= 0 or training_proportion > 100:\n",
    "        print(\"Error! Invalid training proportion\")\n",
    "        return\n",
    "      if training_proportion == 1:\n",
    "        print(\"Error! No testing data available\")\n",
    "        return\n",
    "      if training_proportion < 0.5:\n",
    "        print(\"Warning: Training dataset may not be sufficiently large\")\n",
    "\n",
    "    dataset_dims = len(self.raw_dataset)\n",
    "    if dataset_dims == 0:\n",
    "      print(\"Error! Invalid Dataset\")\n",
    "      return\n",
    "    #=========================================================================================\n",
    "\n",
    "    print(\"=================================================\")\n",
    "    print(\"Beginning our experiment\")\n",
    "    print(\"=================================================\")\n",
    "    print(\"\")\n",
    "    self.prepare_models()\n",
    "    self.train_models()\n",
    "    our_samples = self.generate_samples()\n",
    "    self.evaluate_models(our_samples)\n",
    "    self.print_model_statistics()\n",
    "    if self.verbose:\n",
    "      print(\"Experiment complete\")\n",
    "      print(\"=========================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5jBckRuDCPOx",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We run our experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BE3AHfFkCOk_",
    "outputId": "d4467f79-46e9-4796-b6ea-882de3b17fd8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n",
      "Experiment Configured. We will test the following models: \n",
      "=========================================\n",
      "   - Neural Network\n",
      "   - Gradient Boosting Ensemble\n",
      "   - Support Vector Machine\n",
      "\n",
      "\n",
      "Iteration # 1  ======================================================||\n",
      "=================================================\n",
      "Beginning our experiment\n",
      "=================================================\n",
      "\n",
      "=========================================\n",
      "Compiling our models\n",
      "=========================================\n",
      "Compiling Neural Network\n",
      "Model Compiled!\n",
      "Compiling Gradient Boosting Ensemble\n",
      "Model Compiled!\n",
      "Compiling Support Vector Machine\n",
      "Model Compiled!\n",
      "\n",
      "=========================================\n",
      "Training our models\n",
      "=========================================\n",
      "Training Neural Network\n",
      "Training Gradient Boosting Ensemble\n",
      "Training Support Vector Machine\n",
      "\n",
      "Model Trained!\n",
      "Model Trained!\n",
      "Model Trained!\n",
      "=========================================\n",
      "Evaluating our models\n",
      "=========================================\n",
      "Evaluating Neural Network\n",
      "Evaluating Gradient Boosting Ensemble\n",
      "Evaluating Support Vector Machine\n",
      "\n",
      "Model Accuracy: 0.9\n",
      "Model Accuracy: 0.9\n",
      "Model Accuracy: 0.9\n",
      "Experiment Results:\n",
      "=========================================\n",
      "Models sorted by accuracy: \n",
      "Neural Network : 90.0 %.\n",
      "Gradient Boosting Ensemble : 90.0 %.\n",
      "Support Vector Machine : 90.0 %.\n",
      "=========================================\n",
      "Experiment complete\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "def main():\n",
    "\n",
    "  # ! Set to true to use experiment real models\n",
    "  production = False\n",
    "\n",
    "  #DRIVER CODE:\n",
    "\n",
    "  #We \"create\" three machine learning models. Currently they do nothing besides store their name\n",
    "  verbose = True #The switch that determines how much text should be printed. True = lots of text + troubleshooter, False = no text\n",
    "  \n",
    "  if production:\n",
    "    first_model = machine_learning_model(model_name = \"Neural Network\", verbose = verbose)\n",
    "    second_model = machine_learning_model(model_name = \"Gradient Boosting Ensemble\", verbose = verbose)\n",
    "    third_model = SupportVectorMachine(model_name = \"Support Vector Machine\", verbose = verbose)\n",
    "  else:\n",
    "    first_model = machine_learning_model(model_name = \"Neural Network\", verbose = verbose)\n",
    "    second_model = machine_learning_model(model_name = \"Gradient Boosting Ensemble\", verbose = verbose)\n",
    "    third_model = machine_learning_model(model_name = \"Support Vector Machine\", verbose = verbose)\n",
    "  \n",
    "  #We \"create\" the array of machine learning models from the first, second, and third model.\n",
    "  machine_learning_models = [first_model, second_model, third_model]\n",
    "\n",
    "  #We grab our dataset. Because we don't have the dataset available yet, it's just an empty array\n",
    "  if production:\n",
    "    dataset_path = '../datasets/MalwareData.csv'\n",
    "    our_dataset = pd.read_csv(filepath_or_buffer=dataset_path, sep=\"|\")\n",
    "  else:\n",
    "    our_dataset = [3]\n",
    "    \n",
    "  #We instantiate our experiment with the machine learning models and that dataset\n",
    "  our_experiment = experiment(array_of_models = machine_learning_models, raw_dataset = our_dataset)\n",
    "\n",
    "  #We define our experiment parameters\n",
    "  training_epochs = 3\n",
    "  training_proportion = 0.7\n",
    "  experiment_iterations = 1\n",
    "  #We run the experiment3\n",
    "  for i in range(0, experiment_iterations):\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"Iteration #\", i + 1, \" ======================================================||\")\n",
    "    #our_experiment.wipe()\n",
    "    our_experiment.begin_experiment(training_epochs = training_epochs, training_proportion = training_proportion, verbose = verbose)\n",
    "\n",
    "#Python main execution\n",
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "53ceb2ad4a8e11d048c50a86360c693e94dcbd9c45d6007ce7dad8f26f703c55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
