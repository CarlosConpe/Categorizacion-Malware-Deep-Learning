{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aWAnSz7mpE10",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "svRj36CkURK2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Machine learning:\n",
    "import tensorflow as tf\n",
    "#C math port\n",
    "import numpy as np\n",
    "#Random integer  generator\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "#           GRADIENT BOOSTING MACHINE\n",
    "# ==============================================================================\n",
    "\n",
    "# Tratamiento de datos\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Gráficos\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Preprocesado y modelado\n",
    "# ==============================================================================\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.inspection import permutation_importance\n",
    "import multiprocessing\n",
    "\n",
    "# Configuración warnings\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings('once')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We import our abstract machine learning model class that we made earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "niuF0YP0HsWX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\contm\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "#Abstract class for machine learning models. We will use this to inherit to specific models and override each method when inherited.\n",
    "class MachineLearningModel:\n",
    "  #CONSTRUCTOR: Currently does nothing besides storing the name we gave it\n",
    "  def __init__(self, * ,model_name, verbose):\n",
    "    self.name = model_name\n",
    "    self.verbose = verbose\n",
    "\n",
    "  #Method for compiling our machine learning model\n",
    "  def compile(self):\n",
    "    if self.verbose:\n",
    "      print(\"Model Compiled!\")\n",
    "\n",
    "  #Method for training our machine learning model. It will use the processed dataset\n",
    "  def train(self, data):\n",
    "    if self.verbose:\n",
    "      print(\"Model Trained!\")\n",
    "    self.training_time = 1000\n",
    "\n",
    "  #Method for evaluating our machine learning model. We use this to compute how accurate it is\n",
    "  def evaluate(self, samples):\n",
    "    for sample in samples:\n",
    "      print(sample)\n",
    "    self.precision = 0.9\n",
    "    self.loss = 0.1\n",
    "    if self.verbose:\n",
    "      print(\"Model Accuracy:\", self.precision)\n",
    "    self.mean_evaluation_time = 10\n",
    "\n",
    "  #Method to run the entire model. This is interface that would be used for any model. \n",
    "  def run_model(self, dataset, samples):\n",
    "    self.compile()\n",
    "    self.train(dataset)\n",
    "    self.evaluate(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1PBzUHbmWY04",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "2. We build a neural network class that inherits from our abstract machine learning model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "gX1_GIWvUF4g",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(MachineLearningModel):\n",
    "  #Not inherited: Method to build neural network based on architecture specifications\n",
    "  def build(self):\n",
    "    layer_array = []\n",
    "    #We attach our input layer into our layer array:\n",
    "    layer_array.append(tf.keras.layers.Flatten(input_shape = self.network_architecture['input_size']))\n",
    "    #We attach our hidden layers into our layer array:\n",
    "    for layer in self.network_architecture['architecture']:\n",
    "      layer_array.append(tf.keras.layers.Dense(layer, activation = \"relu\"))\n",
    "    #We attach our output layer into our layer array\n",
    "    layer_array.append(tf.keras.layers.Dense(self.network_architecture['output_size']))\n",
    "    #We create a neural network model using the layer array specifications. self.model is our actual network\n",
    "    self.model = tf.keras.Sequential(layer_array)\n",
    "\n",
    "  #Constructor:\n",
    "  def __init__(self, *, architecture, input_size, output_size, epochs, name, verbose):\n",
    "    #We inherit from the machine learning model class:\n",
    "    super(NeuralNetwork, self).__init__(model_name = name, verbose = verbose)\n",
    "    #We create a dictionary/hash map with the properties of our neural network\n",
    "    self.network_architecture = {'architecture': architecture, \n",
    "                                 'input_size': input_size, \n",
    "                                 'output_size': output_size, \n",
    "                                 'epochs': epochs}\n",
    "    #We build our neural network based on the specifications\n",
    "    self.build()\n",
    "\n",
    "  #We compile the built neural network\n",
    "  def compile(self):\n",
    "    our_optimizer = 'adam'\n",
    "    our_metric = 'accuracy'\n",
    "    self.model.compile(optimizer = our_optimizer, loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True), metrics = [our_metric])\n",
    "  \n",
    "  #We train our neural network with a given dataset\n",
    "  def train(self, *, training_data, training_labels):\n",
    "    self.model.fit(training_data, training_labels, epochs = self.network_architecture['epochs'])\n",
    "    \n",
    "  #We check how accurate our neural network is\n",
    "  def evaluate(self, samples):\n",
    "    testing_labels = samples['testing_labels']\n",
    "    testing_data = samples['testing_data']\n",
    "\n",
    "    probability_model = tf.keras.Sequential([self.model, tf.keras.layers.Softmax()])\n",
    "    predictions = probability_model.predict(testing_data)\n",
    "\n",
    "    correct_guesses = 0\n",
    "    for i in range(0,len(testing_labels)):\n",
    "      if testing_labels[i] == np.argmax(probability_model.predict(np.expand_dims(testing_data[i],0))):\n",
    "        correct_guesses += 1\n",
    "    self.accuracy = correct_guesses / len(testing_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "class SupportVectorMachine(MachineLearningModel):\n",
    "    \n",
    "    def __init__(self,name,verbose):\n",
    "        super(SupportVectorMachine, self).__init__(model_name = name, verbose = verbose)\n",
    "\n",
    "    \"\"\"\n",
    "    Build classifier\n",
    "    :param regularization: Regularization parameter. The strength of the regularization is inversely \n",
    "    proportional to C. Must be strictly positive.\n",
    "    :param kernel: Specifies the kernel type to be used in the algorithm.\n",
    "    :param degree: Degree of the polynomial kernel function (poly). Ignored by all other kernels.\n",
    "    :param gamma{scale, auto} : Kernel coefficient for rbf, poly and sigmoid.\n",
    "    \"\"\"     \n",
    "    def build(self, regularization=1.0, kernel='rbf', degree=3, gamma='scale'):\n",
    "        self.clf = SVC(C=regularization,kernel=kernel, degree=degree, gamma= gamma) \n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        # fit classifier to training set\n",
    "        self.clf.fit(X_train,y_train)\n",
    "    \n",
    "    def evaluate(self, samples):\n",
    "        y_predict = self.clf.predict(samples)\n",
    "        return y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING SVM CLASS - PULSAR STARTS DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "Model accuracy score with default hyperparameters: 0.9827\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = '../datasets/pulsar_stars.csv'\n",
    "df = pd.read_csv(data)\n",
    "\n",
    "# remove leading spaces from column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# rename column names\n",
    "df.columns = ['IP Mean', 'IP Sd', 'IP Kurtosis', 'IP Skewness','DM-SNR Mean', 'DM-SNR Sd', 'DM-SNR Kurtosis', 'DM-SNR Skewness', 'target_class']\n",
    "\n",
    "\n",
    "# check distribution of target_class column\n",
    "df['target_class'].value_counts()\n",
    "\n",
    "X = df.drop(['target_class'], axis=1)\n",
    "y = df['target_class']\n",
    "\n",
    "# split X and y into training and testing sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "cols = X_train.columns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns=[cols])\n",
    "X_test = pd.DataFrame(X_test, columns=[cols])\n",
    "\n",
    "svm = SupportVectorMachine(name=\"TESTING SVM\",verbose=False)\n",
    "svm.build()\n",
    "svm.train(X_train, y_train)\n",
    "train = svm.evaluate(X_test)\n",
    "\n",
    "print(train)\n",
    "\n",
    "print('Model accuracy score with default hyperparameters: {0:0.4f}'. format(accuracy_score(y_test, train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING SVM CLASS - MALWARE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\contm\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>md5</th>\n",
       "      <th>Machine</th>\n",
       "      <th>SizeOfOptionalHeader</th>\n",
       "      <th>Characteristics</th>\n",
       "      <th>MajorLinkerVersion</th>\n",
       "      <th>MinorLinkerVersion</th>\n",
       "      <th>SizeOfCode</th>\n",
       "      <th>SizeOfInitializedData</th>\n",
       "      <th>SizeOfUninitializedData</th>\n",
       "      <th>...</th>\n",
       "      <th>ResourcesNb</th>\n",
       "      <th>ResourcesMeanEntropy</th>\n",
       "      <th>ResourcesMinEntropy</th>\n",
       "      <th>ResourcesMaxEntropy</th>\n",
       "      <th>ResourcesMeanSize</th>\n",
       "      <th>ResourcesMinSize</th>\n",
       "      <th>ResourcesMaxSize</th>\n",
       "      <th>LoadConfigurationSize</th>\n",
       "      <th>VersionInformationSize</th>\n",
       "      <th>legitimate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>memtest.exe</td>\n",
       "      <td>631ea355665f28d4707448e442fbf5b8</td>\n",
       "      <td>332</td>\n",
       "      <td>224</td>\n",
       "      <td>258</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>361984</td>\n",
       "      <td>115712</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3.262823</td>\n",
       "      <td>2.568844</td>\n",
       "      <td>3.537939</td>\n",
       "      <td>8797.000000</td>\n",
       "      <td>216</td>\n",
       "      <td>18032</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ose.exe</td>\n",
       "      <td>9d10f99a6712e28f8acd5641e3a7ea6b</td>\n",
       "      <td>332</td>\n",
       "      <td>224</td>\n",
       "      <td>3330</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>130560</td>\n",
       "      <td>19968</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4.250461</td>\n",
       "      <td>3.420744</td>\n",
       "      <td>5.080177</td>\n",
       "      <td>837.000000</td>\n",
       "      <td>518</td>\n",
       "      <td>1156</td>\n",
       "      <td>72</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>setup.exe</td>\n",
       "      <td>4d92f518527353c0db88a70fddcfd390</td>\n",
       "      <td>332</td>\n",
       "      <td>224</td>\n",
       "      <td>3330</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>517120</td>\n",
       "      <td>621568</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>4.426324</td>\n",
       "      <td>2.846449</td>\n",
       "      <td>5.271813</td>\n",
       "      <td>31102.272727</td>\n",
       "      <td>104</td>\n",
       "      <td>270376</td>\n",
       "      <td>72</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DW20.EXE</td>\n",
       "      <td>a41e524f8d45f0074fd07805ff0c9b12</td>\n",
       "      <td>332</td>\n",
       "      <td>224</td>\n",
       "      <td>258</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>585728</td>\n",
       "      <td>369152</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>4.364291</td>\n",
       "      <td>2.669314</td>\n",
       "      <td>6.400720</td>\n",
       "      <td>1457.000000</td>\n",
       "      <td>90</td>\n",
       "      <td>4264</td>\n",
       "      <td>72</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dwtrig20.exe</td>\n",
       "      <td>c87e561258f2f8650cef999bf643a731</td>\n",
       "      <td>332</td>\n",
       "      <td>224</td>\n",
       "      <td>258</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>294912</td>\n",
       "      <td>247296</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4.306100</td>\n",
       "      <td>3.421598</td>\n",
       "      <td>5.190603</td>\n",
       "      <td>1074.500000</td>\n",
       "      <td>849</td>\n",
       "      <td>1300</td>\n",
       "      <td>72</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name                               md5  Machine  \\\n",
       "0   memtest.exe  631ea355665f28d4707448e442fbf5b8      332   \n",
       "1       ose.exe  9d10f99a6712e28f8acd5641e3a7ea6b      332   \n",
       "2     setup.exe  4d92f518527353c0db88a70fddcfd390      332   \n",
       "3      DW20.EXE  a41e524f8d45f0074fd07805ff0c9b12      332   \n",
       "4  dwtrig20.exe  c87e561258f2f8650cef999bf643a731      332   \n",
       "\n",
       "   SizeOfOptionalHeader  Characteristics  MajorLinkerVersion  \\\n",
       "0                   224              258                   9   \n",
       "1                   224             3330                   9   \n",
       "2                   224             3330                   9   \n",
       "3                   224              258                   9   \n",
       "4                   224              258                   9   \n",
       "\n",
       "   MinorLinkerVersion  SizeOfCode  SizeOfInitializedData  \\\n",
       "0                   0      361984                 115712   \n",
       "1                   0      130560                  19968   \n",
       "2                   0      517120                 621568   \n",
       "3                   0      585728                 369152   \n",
       "4                   0      294912                 247296   \n",
       "\n",
       "   SizeOfUninitializedData  ...  ResourcesNb  ResourcesMeanEntropy  \\\n",
       "0                        0  ...            4              3.262823   \n",
       "1                        0  ...            2              4.250461   \n",
       "2                        0  ...           11              4.426324   \n",
       "3                        0  ...           10              4.364291   \n",
       "4                        0  ...            2              4.306100   \n",
       "\n",
       "   ResourcesMinEntropy  ResourcesMaxEntropy  ResourcesMeanSize  \\\n",
       "0             2.568844             3.537939        8797.000000   \n",
       "1             3.420744             5.080177         837.000000   \n",
       "2             2.846449             5.271813       31102.272727   \n",
       "3             2.669314             6.400720        1457.000000   \n",
       "4             3.421598             5.190603        1074.500000   \n",
       "\n",
       "   ResourcesMinSize  ResourcesMaxSize  LoadConfigurationSize  \\\n",
       "0               216             18032                      0   \n",
       "1               518              1156                     72   \n",
       "2               104            270376                     72   \n",
       "3                90              4264                     72   \n",
       "4               849              1300                     72   \n",
       "\n",
       "   VersionInformationSize  legitimate  \n",
       "0                      16           1  \n",
       "1                      18           1  \n",
       "2                      18           1  \n",
       "3                      18           1  \n",
       "4                      18           1  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = '../datasets/MalwareData.csv'\n",
    "df = pd.read_csv(filepath_or_buffer=data, sep=\"|\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\contm\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 138047 entries, 0 to 138046\n",
      "Data columns (total 57 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   Name                         138047 non-null  object \n",
      " 1   md5                          138047 non-null  object \n",
      " 2   Machine                      138047 non-null  int64  \n",
      " 3   SizeOfOptionalHeader         138047 non-null  int64  \n",
      " 4   Characteristics              138047 non-null  int64  \n",
      " 5   MajorLinkerVersion           138047 non-null  int64  \n",
      " 6   MinorLinkerVersion           138047 non-null  int64  \n",
      " 7   SizeOfCode                   138047 non-null  int64  \n",
      " 8   SizeOfInitializedData        138047 non-null  int64  \n",
      " 9   SizeOfUninitializedData      138047 non-null  int64  \n",
      " 10  AddressOfEntryPoint          138047 non-null  int64  \n",
      " 11  BaseOfCode                   138047 non-null  int64  \n",
      " 12  BaseOfData                   138047 non-null  int64  \n",
      " 13  ImageBase                    138047 non-null  float64\n",
      " 14  SectionAlignment             138047 non-null  int64  \n",
      " 15  FileAlignment                138047 non-null  int64  \n",
      " 16  MajorOperatingSystemVersion  138047 non-null  int64  \n",
      " 17  MinorOperatingSystemVersion  138047 non-null  int64  \n",
      " 18  MajorImageVersion            138047 non-null  int64  \n",
      " 19  MinorImageVersion            138047 non-null  int64  \n",
      " 20  MajorSubsystemVersion        138047 non-null  int64  \n",
      " 21  MinorSubsystemVersion        138047 non-null  int64  \n",
      " 22  SizeOfImage                  138047 non-null  int64  \n",
      " 23  SizeOfHeaders                138047 non-null  int64  \n",
      " 24  CheckSum                     138047 non-null  int64  \n",
      " 25  Subsystem                    138047 non-null  int64  \n",
      " 26  DllCharacteristics           138047 non-null  int64  \n",
      " 27  SizeOfStackReserve           138047 non-null  int64  \n",
      " 28  SizeOfStackCommit            138047 non-null  int64  \n",
      " 29  SizeOfHeapReserve            138047 non-null  int64  \n",
      " 30  SizeOfHeapCommit             138047 non-null  int64  \n",
      " 31  LoaderFlags                  138047 non-null  int64  \n",
      " 32  NumberOfRvaAndSizes          138047 non-null  int64  \n",
      " 33  SectionsNb                   138047 non-null  int64  \n",
      " 34  SectionsMeanEntropy          138047 non-null  float64\n",
      " 35  SectionsMinEntropy           138047 non-null  float64\n",
      " 36  SectionsMaxEntropy           138047 non-null  float64\n",
      " 37  SectionsMeanRawsize          138047 non-null  float64\n",
      " 38  SectionsMinRawsize           138047 non-null  int64  \n",
      " 39  SectionMaxRawsize            138047 non-null  int64  \n",
      " 40  SectionsMeanVirtualsize      138047 non-null  float64\n",
      " 41  SectionsMinVirtualsize       138047 non-null  int64  \n",
      " 42  SectionMaxVirtualsize        138047 non-null  int64  \n",
      " 43  ImportsNbDLL                 138047 non-null  int64  \n",
      " 44  ImportsNb                    138047 non-null  int64  \n",
      " 45  ImportsNbOrdinal             138047 non-null  int64  \n",
      " 46  ExportNb                     138047 non-null  int64  \n",
      " 47  ResourcesNb                  138047 non-null  int64  \n",
      " 48  ResourcesMeanEntropy         138047 non-null  float64\n",
      " 49  ResourcesMinEntropy          138047 non-null  float64\n",
      " 50  ResourcesMaxEntropy          138047 non-null  float64\n",
      " 51  ResourcesMeanSize            138047 non-null  float64\n",
      " 52  ResourcesMinSize             138047 non-null  int64  \n",
      " 53  ResourcesMaxSize             138047 non-null  int64  \n",
      " 54  LoadConfigurationSize        138047 non-null  int64  \n",
      " 55  VersionInformationSize       138047 non-null  int64  \n",
      " 56  legitimate                   138047 non-null  int64  \n",
      "dtypes: float64(10), int64(45), object(2)\n",
      "memory usage: 60.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# view summary of dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((110437, 54), (27610, 54))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(['legitimate','Name','md5'], axis=1)\n",
    "y = df['legitimate']\n",
    "\n",
    "# split X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with rbf kernel and C=1000.0 : 0.7032\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# instantiate classifier with default hyperparameters\n",
    "svc=SVC() \n",
    "\n",
    "# fit classifier to training set\n",
    "svc.fit(X_train,y_train)\n",
    "\n",
    "# make predictions on test set\n",
    "y_pred=svc.predict(X_test)\n",
    "\n",
    "# compute and print accuracy score\n",
    "print('Model accuracy score : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting Machine Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\contm\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "#Abstract class for machine learning models. We will use this to inherit to specific models and override each method when inherited.\n",
    "class GradientBoostingMachine(MachineLearningModel):\n",
    "    #Constructor\n",
    "    def __init__(self,name,verbose):\n",
    "         super(GradientBoostingMachine, self).__init__(model_name = name, verbose = verbose)\n",
    "\n",
    "    def build(self, n_estimators = [50, 100, 500, 1000], max_features = ['auto', 'sqrt', 'log2'], max_depth = [None, 1, 3, 5, 10, 20], subsample = [0.5, 1], learning_rate = [0.001, 0.01, 0.1]):\n",
    "        self.param_grid = {\n",
    "            'n_estimators'  : n_estimators,\n",
    "            'max_features'  : max_features,\n",
    "            'max_depth'     : max_depth,\n",
    "            'subsample'     : subsample,\n",
    "            'learning_rate' : learning_rate\n",
    "        }\n",
    "\n",
    "        self.grid = GridSearchCV(\n",
    "            estimator  = GradientBoostingClassifier(random_state=123),\n",
    "            param_grid = self.param_grid,\n",
    "            scoring    = 'accuracy',\n",
    "            n_jobs     = multiprocessing.cpu_count() - 1,\n",
    "            cv         = RepeatedKFold(n_splits=3, n_repeats=1, random_state=123), \n",
    "            refit      = True,\n",
    "            verbose    = 0,\n",
    "            return_train_score = True\n",
    "       )\n",
    "\n",
    "    \n",
    "    def train(self, x_train , y_train):\n",
    "        self.grid.fit(X = x_train, y = y_train) \n",
    "        # Resultados\n",
    "        # ==============================================================================\n",
    "        resultados = pd.DataFrame(self.grid.cv_results_)\n",
    "        resultados.filter(regex = '(param*|mean_t|std_t)') \\\n",
    "            .drop(columns = 'params') \\\n",
    "            .sort_values('mean_test_score', ascending = False) \\\n",
    "            .head(4)\n",
    "\n",
    "        # Mejores hiperparámetros por validación cruzada\n",
    "        # ==============================================================================\n",
    "        print(\"----------------------------------------\")\n",
    "        print(\"Mejores hiperparámetros encontrados (cv)\")\n",
    "        print(\"----------------------------------------\")\n",
    "        print(self.grid.best_params_, \":\", self.grid.best_score_, self.grid.scoring)\n",
    "\n",
    "        self.modelo_final = self.grid.best_estimator_\n",
    "\n",
    "        \n",
    "    def evaluate(self, x_test, y_test):\n",
    "        # Error de test del modelo final\n",
    "        # ==============================================================================\n",
    "        self.predicciones = self.modelo_final.predict(X = x_test)\n",
    "        self.predicciones[:10]\n",
    "\n",
    "        self.mat_confusion = confusion_matrix(\n",
    "                    y_true    = y_test,\n",
    "                    y_pred    = self.predicciones\n",
    "                )\n",
    "\n",
    "        self.accuracy = accuracy_score(\n",
    "                    y_true    = y_test,\n",
    "                    y_pred    = self.predicciones,\n",
    "                    normalize = True\n",
    "                )\n",
    "\n",
    "        print(\"Matriz de confusión\")\n",
    "        print(\"-------------------\")\n",
    "        print(self.mat_confusion)\n",
    "        print(\"\")\n",
    "        print(f\"El accuracy del test es: {100 * self.accuracy} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Our GBM Model With Car Sales from R Library Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. container::\n",
      "\n",
      "   ======== ===============\n",
      "   Carseats R Documentation\n",
      "   ======== ===============\n",
      "\n",
      "   .. rubric:: Sales of Child Car Seats\n",
      "      :name: sales-of-child-car-seats\n",
      "\n",
      "   .. rubric:: Description\n",
      "      :name: description\n",
      "\n",
      "   A simulated data set containing sales of child car seats at 400\n",
      "   different stores.\n",
      "\n",
      "   .. rubric:: Usage\n",
      "      :name: usage\n",
      "\n",
      "   ::\n",
      "\n",
      "      Carseats\n",
      "\n",
      "   .. rubric:: Format\n",
      "      :name: format\n",
      "\n",
      "   A data frame with 400 observations on the following 11 variables.\n",
      "\n",
      "   ``Sales``\n",
      "      Unit sales (in thousands) at each location\n",
      "\n",
      "   ``CompPrice``\n",
      "      Price charged by competitor at each location\n",
      "\n",
      "   ``Income``\n",
      "      Community income level (in thousands of dollars)\n",
      "\n",
      "   ``Advertising``\n",
      "      Local advertising budget for company at each location (in\n",
      "      thousands of dollars)\n",
      "\n",
      "   ``Population``\n",
      "      Population size in region (in thousands)\n",
      "\n",
      "   ``Price``\n",
      "      Price company charges for car seats at each site\n",
      "\n",
      "   ``ShelveLoc``\n",
      "      A factor with levels ``Bad``, ``Good`` and ``Medium`` indicating\n",
      "      the quality of the shelving location for the car seats at each\n",
      "      site\n",
      "\n",
      "   ``Age``\n",
      "      Average age of the local population\n",
      "\n",
      "   ``Education``\n",
      "      Education level at each location\n",
      "\n",
      "   ``Urban``\n",
      "      A factor with levels ``No`` and ``Yes`` to indicate whether the\n",
      "      store is in an urban or rural location\n",
      "\n",
      "   ``US``\n",
      "      A factor with levels ``No`` and ``Yes`` to indicate whether the\n",
      "      store is in the US or not\n",
      "\n",
      "   .. rubric:: Source\n",
      "      :name: source\n",
      "\n",
      "   Simulated data\n",
      "\n",
      "   .. rubric:: References\n",
      "      :name: references\n",
      "\n",
      "   James, G., Witten, D., Hastie, T., and Tibshirani, R. (2013) *An\n",
      "   Introduction to Statistical Learning with applications in R*,\n",
      "   https://www.statlearning.com, Springer-Verlag, New York\n",
      "\n",
      "   .. rubric:: Examples\n",
      "      :name: examples\n",
      "\n",
      "   ::\n",
      "\n",
      "      summary(Carseats)\n",
      "      lm.fit=lm(Sales~Advertising+Price,data=Carseats)\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'OneHotEncoder' object has no attribute 'get_feature_names_out'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-25f1b20ccbc2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;31m# ==============================================================================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m# Nombre de todas las columnas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m \u001b[0mencoded_cat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamed_transformers_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'onehot'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names_out\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcat_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnumeric_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoded_cat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'OneHotEncoder' object has no attribute 'get_feature_names_out'"
     ]
    }
   ],
   "source": [
    "#Charge Dataset\n",
    "carseats = sm.datasets.get_rdataset(\"Carseats\", \"ISLR\")\n",
    "datos = carseats.data\n",
    "print(carseats.__doc__)\n",
    "\n",
    "#Configure the data for classification \n",
    "datos['ventas_altas'] = np.where(datos.Sales > 8, 0, 1) #Clasificar si venden mucho o poco\n",
    "# Una vez creada la nueva variable respuesta se descarta la original\n",
    "datos = datos.drop(columns = 'Sales')\n",
    "\n",
    "\n",
    "\n",
    "# DATA PREPROCESING\n",
    "\n",
    "# División de los datos en train y test\n",
    "# ==============================================================================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                        datos.drop(columns = 'ventas_altas'),\n",
    "                                        datos['ventas_altas'],\n",
    "                                        random_state = 123,\n",
    "                                    )\n",
    "\n",
    "# One-hot-encoding de las variables categóricas\n",
    "# ==============================================================================\n",
    "# Se identifica el nombre de las columnas numéricas y categóricas\n",
    "cat_cols = X_train.select_dtypes(include=['object', 'category']).columns.to_list()\n",
    "numeric_cols = X_train.select_dtypes(include=['float64', 'int']).columns.to_list()\n",
    "\n",
    "# Se aplica one-hot-encoding solo a las columnas categóricas\n",
    "preprocessor = ColumnTransformer(\n",
    "                    [('onehot', OneHotEncoder(handle_unknown='ignore'), cat_cols)],\n",
    "                    remainder='passthrough'\n",
    "               )\n",
    "\n",
    "# Una vez que se ha definido el objeto ColumnTransformer, con el método fit()\n",
    "# se aprenden las transformaciones con los datos de entrenamiento y se aplican a\n",
    "# los dos conjuntos con transform(). Ambas operaciones a la vez con fit_transform().\n",
    "X_train_prep = preprocessor.fit_transform(X_train)\n",
    "X_test_prep  = preprocessor.transform(X_test)\n",
    "\n",
    "# Convertir el output del ColumnTransformer en dataframe y añadir el nombre de las columnas\n",
    "# ==============================================================================\n",
    "# Nombre de todas las columnas\n",
    "encoded_cat = preprocessor.named_transformers_['onehot'].get_feature_names_out(cat_cols)\n",
    "labels = np.concatenate([numeric_cols, encoded_cat])\n",
    "\n",
    "# Conversión a dataframe\n",
    "X_train_prep = pd.DataFrame(X_train_prep, columns=labels)\n",
    "X_test_prep  = pd.DataFrame(X_test_prep, columns=labels)\n",
    "X_train_prep.info()\n",
    "\n",
    "\n",
    "gbm = GradientBoostingMachine(name=\"TESTING SVM\",verbose=False)\n",
    "gbm.build()\n",
    "gbm.train(X_train_prep, y_train)\n",
    "train = gbm.evaluate(X_test_prep,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSjYiGvTid7h",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "3. We create an ensamble class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wAFcAyCRinuT",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#In the simplest form, an ensamble is an array of N machine learning models\n",
    "#The ensamble class should therefore operate as an array container class\n",
    "\n",
    "class Ensamble(MachineLearningModel):\n",
    "  def build(self, ensamble_size):\n",
    "    self.array = []\n",
    "    for i in range(0, ensamble_size):\n",
    "      model_id = '' + i\n",
    "      self.array.append(self.model_type)\n",
    "\n",
    "  def __init__(self, *, ensamble_size, model_type, name, verbose):\n",
    "      super(Ensamble, self).__init__(model_name = name, verbose = verbose)\n",
    "      self.size = ensamble_size\n",
    "      self.model_type = model_type\n",
    "      #self.build(ensamble_size)\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ryQNS-2Rmi0v",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "4. We create a data parser class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "18YQGsERmkkQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#This class will process data and adapt it to something a given model can work with\n",
    "#VERY UNFINISHED!!! Currently has minimum requirements for neural network compatibility\n",
    "class DataParser:\n",
    "  #We store the dataset during the construction phase\n",
    "  def __init__(self, data_src):\n",
    "    self.data_src = data_src\n",
    "    self.neural_network_dataset = None\n",
    "    self.testing_samples = None\n",
    "\n",
    "#We will use this method to compute the number of unique labels. Currently not functional!!!\n",
    "  def get_unique_labels(self):\n",
    "    return 10\n",
    "\n",
    "  #Method to distribute and preprocess data\n",
    "  def preprocess(self, *, training, testing):\n",
    "    self.training_size = training\n",
    "    self.testing_size = testing\n",
    "    (self.training_data, self.training_labels), (self.testing_data, self.testing_labels) = self.data_src.load_data()\n",
    "    self.training_data = self.training_data / 255\n",
    "    self.testing_data = self.testing_data / 255\n",
    "    self.data_shape = self.training_data[0].shape\n",
    "    self.output_shape = self.get_unique_labels()\n",
    "\n",
    "  #Method to print dataset information\n",
    "  def print_dataset_info(self):\n",
    "    print(\"Dataset properties: \")\n",
    "    print(\"\\tSize: \", len(self.data_src[0]))\n",
    "    print(\"\\tParameters:\", len(self.data_src))\n",
    "\n",
    "  def generate_testing_samples(self, *, sample_size):\n",
    "    if self.testing_samples == None:\n",
    "      samples = {}\n",
    "      testing_labels = []\n",
    "      testing_data = []\n",
    "      for i in range(0, min(sample_size, len(self.testing_labels))):\n",
    "        random_index = randint(0, min(sample_size, len(self.testing_labels)))\n",
    "        testing_labels.append(self.testing_labels[random_index])\n",
    "        testing_data.append(self.testing_data[random_index])\n",
    "\n",
    "      testing_labels = np.array(testing_labels)\n",
    "      testing_data = np.array(testing_data)\n",
    "      samples['testing_labels'] = testing_labels\n",
    "      samples['testing_data'] = testing_data\n",
    "\n",
    "      self.testing_samples = samples\n",
    "      return self.testing_samples\n",
    "\n",
    "\n",
    "  #We convert our dataset into one compatible with a sequential neural network\n",
    "  def convert_to_neural_network(self):\n",
    "    if self.neural_network_dataset == None:\n",
    "      self.neural_network_dataset = self.data_src\n",
    "    return self.neural_network_dataset\n",
    "  \n",
    "  #Future implementations\n",
    "  def convert_to_cnn(self):\n",
    "    pass\n",
    "\n",
    "  def convert_to_kernel(self):\n",
    "    pass\n",
    "\n",
    "  def convert_to_svm(self):\n",
    "    pass\n",
    "\n",
    "  def convert_to_gradient_ascent(self):\n",
    "    pass\n",
    "  \n",
    "  def convert_to_gradient_descent(self):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eKcThHFbmASR",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "5. We instantiate tests of our classes and see if they are storing information correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5kv-31rIIZFs",
    "outputId": "4df893c8-970a-4e10-f2e8-20394cd1f295",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test ensamble\n",
      "test neural network\n",
      "<__main__.NeuralNetwork object at 0x000002E2AD982920>\n"
     ]
    }
   ],
   "source": [
    "#We create a test neural network\n",
    "our_network = NeuralNetwork(\n",
    "    architecture = [3, 2, 4], \n",
    "    input_size = (8, 8), \n",
    "    output_size = 10, \n",
    "    epochs = 3, \n",
    "    name = \"test neural network\", \n",
    "    verbose = False)\n",
    "\n",
    "#We create a test ensamble of the type of our neural network\n",
    "our_ensamble = Ensamble(\n",
    "    ensamble_size = 10,\n",
    "    model_type = our_network,\n",
    "    name = \"test ensamble\",\n",
    "    verbose = False)\n",
    "\n",
    "#We check to see if our models are storing information correctly\n",
    "print(our_ensamble.name)\n",
    "print(our_network.name)\n",
    "print(our_ensamble.model_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zfi97iA4Sthc",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "6. Now that we know the model classes are behaving correctly, we perform a test run of our data parser on a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RjVWv-4gStAe",
    "outputId": "55ae77e8-cbe4-42ae-f1e2-ca85329a2c5b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2350 - accuracy: 0.9313\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1017 - accuracy: 0.9691\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0703 - accuracy: 0.9783\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Network accuracy:  99.0\n"
     ]
    }
   ],
   "source": [
    "#We create an instance of our data parser, we will use the MNIST dataset to test\n",
    "our_parser = DataParser(tf.keras.datasets.mnist)\n",
    "\n",
    "#Parser creates training and testing dataset from original dataset\n",
    "our_parser.preprocess(training = 0.7, testing = 0.3)\n",
    "\n",
    "#We create a neural network that is compatible with our testing dataset\n",
    "mnist_network = NeuralNetwork(\n",
    "    architecture = [128, 64], \n",
    "    input_size = our_parser.data_shape, \n",
    "    output_size = our_parser.output_shape, \n",
    "    epochs = 3, \n",
    "    name = \"MNIST neural network\", \n",
    "    verbose = False)\n",
    "\n",
    "#We compile our network according to the construction specifications\n",
    "mnist_network.compile()\n",
    "\n",
    "#We train our neural network with a dataset made for neural networks by our parser\n",
    "mnist_network.train(training_data = our_parser.training_data, training_labels = our_parser.training_labels)\n",
    "\n",
    "#We check how accurate our model is. If its around 90+% then it is very accurate\n",
    "mnist_network.evaluate(our_parser.generate_testing_samples(sample_size = 300))\n",
    "print(\"Network accuracy: \", 100* mnist_network.accuracy)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "53ceb2ad4a8e11d048c50a86360c693e94dcbd9c45d6007ce7dad8f26f703c55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
