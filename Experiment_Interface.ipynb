{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "We create an abstract machine learning class. Every machine learning model we use will inherit from this. We can observe that it has no real functionality as-is besides for giving us an idea of the interface. \n"
   ],
   "metadata": {
    "id": "nTkSrr9uQ46Y",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#Abstract class for machine learning models. We will use this to inherit to specific models and override each method when inherited.\n",
    "class machine_learning_model:\n",
    "  #CONSTRUCTOR: Currently does nothing besides storing the name we gave it\n",
    "  def __init__(self, * ,model_name, verbose):\n",
    "    self.name = model_name\n",
    "    self.verbose = verbose\n",
    "\n",
    "  #Method for compiling our machine learning model\n",
    "  def compile(self):\n",
    "    if self.verbose:\n",
    "      print(\"Model Compiled!\")\n",
    "\n",
    "  #Method to process our data such that it is usable by our model\n",
    "  def parse_data(self, dataset):\n",
    "    self.processed_dataset = []\n",
    "    #We choose to store the processed data in our model. This might have to change later depending on RAM consumption for this process...\n",
    "    if self.verbose:\n",
    "      print(\"Data Processed!\")\n",
    "\n",
    "  #Method for training our machine learning model. It will use the processed dataset\n",
    "  def train(self):\n",
    "    if self.verbose:\n",
    "      print(\"Model Trained!\")\n",
    "    self.training_time = 1000\n",
    "\n",
    "  #Method for evaluating our machine learning model. We use this to compute how accurate it is\n",
    "  def evaluate(self, samples):\n",
    "    for sample in samples:\n",
    "      print(sample)\n",
    "    self.precision = 0.9\n",
    "    self.loss = 0.1\n",
    "    if self.verbose:\n",
    "      print(\"Model Accuracy:\", self.precision)\n",
    "    self.mean_evaluation_time = 10\n",
    "\n",
    "  #Method to run the entire model. This is interface that would be used for any model. \n",
    "  def run_model(self, dataset, samples):\n",
    "    self.compile()\n",
    "    self.parse_data(dataset)\n",
    "    self.train()\n",
    "    self.evaluate(samples)"
   ],
   "metadata": {
    "id": "k-UbT5AXP6hT",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "We create an experiment class. We will create an experiment which will be in charge of evaluating our different AI models."
   ],
   "metadata": {
    "id": "yFcSn1V4NKAk",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iHfTFCVkNHdk",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#This class will be used to run instances of our experiment. We can run as many experiments as we would like\n",
    "class experiment:\n",
    "  #Helper function for constructor(Used to print the name of our models)\n",
    "  def print_model_ids(self):\n",
    "    for model in self.array_of_models:\n",
    "      print(\"   -\", model.name)\n",
    "\n",
    "  #CONSTRUCTOR: We store the dataset and models we will use for the experiment\n",
    "  def __init__(self, *, array_of_models, raw_dataset):\n",
    "    self.array_of_models = array_of_models\n",
    "    self.raw_dataset = raw_dataset\n",
    "    print(\"=========================================\")\n",
    "    print(\"Experiment Configured. We will test the following models: \")\n",
    "    print(\"=========================================\")\n",
    "    self.print_model_ids()\n",
    "\n",
    "  #We prepare our models by compiling them\n",
    "  def prepare_models(self):\n",
    "    if self.verbose:\n",
    "      print(\"=========================================\")\n",
    "      print(\"Compiling our models\")\n",
    "      print(\"=========================================\")\n",
    "      for model in self.array_of_models:\n",
    "        print(\"Compiling\", model.name)\n",
    "        model.compile()\n",
    "      print(\"\")\n",
    "\n",
    "  #We train our models with the dataset\n",
    "  def train_models(self):\n",
    "    if self.verbose:\n",
    "      print(\"=========================================\")\n",
    "      print(\"Training our models\")\n",
    "      print(\"=========================================\")\n",
    "      for model in self.array_of_models:\n",
    "        print(\"Training\", model.name)\n",
    "      print(\"\")\n",
    "    for model in self.array_of_models:\n",
    "      model.train()\n",
    "  \n",
    "  #We evaluate the precision of our models\n",
    "  def evaluate_models(self, our_samples):\n",
    "    if self.verbose:\n",
    "      print(\"=========================================\")\n",
    "      print(\"Evaluating our models\")\n",
    "      print(\"=========================================\")\n",
    "      for model in self.array_of_models:\n",
    "        print(\"Evaluating\", model.name)\n",
    "      print(\"\")\n",
    "    for model in self.array_of_models:\n",
    "      model.evaluate(our_samples)\n",
    "\n",
    "  #Method to sort our arrays by accuracy!!!!\n",
    "  def sort_models(self):\n",
    "    array_sorted_by_precision = sorted(self.array_of_models, key = lambda model: model.precision, reverse = True)\n",
    "    return array_sorted_by_precision\n",
    "\n",
    "  #We print the results of the experiment. We are sorting based on accuracy of the model when evaluating.\n",
    "  #Supported sorting metrics: training time, evaluation time, accuracy, loss.\n",
    "  #To implement: memory consumption, complexity of model, more?\n",
    "  def print_model_statistics(self):\n",
    "    print(\"Experiment Results:\")\n",
    "    print(\"=========================================\")\n",
    "    best_models = self.sort_models()\n",
    "    print(\"Models sorted by accuracy: \")\n",
    "    for model in best_models:\n",
    "      print(model.name, \":\", model.precision * 100, \"%.\")\n",
    "    print(\"=========================================\")\n",
    "  \n",
    "  #Method to generate samples for accuracy testing. We randomly select samples from our dataset\n",
    "  def generate_samples(self):\n",
    "    our_samples = []\n",
    "    return our_samples\n",
    "\n",
    "  #ACTUAL EXPERIMENT CALL: In this method we are running our experiment.\n",
    "  def begin_experiment(self, *,  training_epochs, training_proportion, verbose):\n",
    "    self.verbose = verbose\n",
    "    #=========================================================================================\n",
    "    #Troubleshooter:\n",
    "    if self.verbose:\n",
    "      if len(self.array_of_models) == 0:\n",
    "        print(\"Error! No models available for testing\")\n",
    "      for i in range(0, len(self.array_of_models)):\n",
    "        if type(self.array_of_models[i]) != machine_learning_model:\n",
    "          print(\"Error! Untestable data has been selected\")\n",
    "          return\n",
    "      training_epochs = int(training_epochs)\n",
    "      if training_epochs < 1:\n",
    "        print(\"Error! Epochs cannot be less than 1\")\n",
    "        return\n",
    "      if training_epochs < 3:\n",
    "        print(\"Warning: Epochs should be at least 3\")\n",
    "\n",
    "      if training_proportion > 1 and training_proportion <= 100:\n",
    "        print(\"Warning: Training proportion should be expressed as a decimal from 0 to 1\")\n",
    "        training_proportion = training_proportion / 100\n",
    "      \n",
    "      if training_proportion <= 0 or training_proportion > 100:\n",
    "        print(\"Error! Invalid training proportion\")\n",
    "        return\n",
    "      if training_proportion == 1:\n",
    "        print(\"Error! No testing data available\")\n",
    "        return\n",
    "      if training_proportion < 0.5:\n",
    "        print(\"Warning: Training dataset may not be sufficiently large\")\n",
    "\n",
    "    dataset_dims = len(self.raw_dataset)\n",
    "    if dataset_dims == 0:\n",
    "      print(\"Error! Invalid Dataset\")\n",
    "      return\n",
    "    #=========================================================================================\n",
    "\n",
    "    print(\"=================================================\")\n",
    "    print(\"Beginning our experiment\")\n",
    "    print(\"=================================================\")\n",
    "    print(\"\")\n",
    "    self.prepare_models()\n",
    "    self.train_models()\n",
    "    our_samples = self.generate_samples()\n",
    "    self.evaluate_models(our_samples)\n",
    "    self.print_model_statistics()\n",
    "    if self.verbose:\n",
    "      print(\"Experiment complete\")\n",
    "      print(\"=========================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We run our experiment:"
   ],
   "metadata": {
    "id": "5jBckRuDCPOx",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def main():\n",
    "  #DRIVER CODE:\n",
    "\n",
    "  #We \"create\" three machine learning models. Currently they do nothing besides store their name\n",
    "  verbose = True #The switch that determines how much text should be printed. True = lots of text + troubleshooter, False = no text\n",
    "  first_model = machine_learning_model(model_name = \"Neural Network\", verbose = verbose)\n",
    "  second_model = machine_learning_model(model_name = \"Gradient Boosting Ensemble\", verbose = verbose)\n",
    "  third_model = machine_learning_model(model_name = \"Support Vector Machine\", verbose = verbose)\n",
    "  #We \"create\" the array of machine learning models from the first, second, and third model.\n",
    "  machine_learning_models = [first_model, second_model, third_model]\n",
    "\n",
    "  #We grab our dataset. Because we don't have the dataset available yet, it's just an empty array\n",
    "  our_dataset = [3]\n",
    "\n",
    "  #We instantiate our experiment with the machine learning models and that dataset\n",
    "  our_experiment = experiment(array_of_models = machine_learning_models, raw_dataset = our_dataset)\n",
    "\n",
    "  #We define our experiment parameters\n",
    "  training_epochs = 3\n",
    "  training_proportion = 0.7\n",
    "  experiment_iterations = 1\n",
    "  #We run the experiment\n",
    "  for i in range(0, experiment_iterations):\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"Iteration #\", i + 1, \" ======================================================||\")\n",
    "    #our_experiment.wipe()\n",
    "    our_experiment.begin_experiment(training_epochs = training_epochs, training_proportion = training_proportion, verbose = verbose)\n",
    "\n",
    "#Python main execution\n",
    "if __name__ == \"__main__\":\n",
    "  main()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BE3AHfFkCOk_",
    "outputId": "d4467f79-46e9-4796-b6ea-882de3b17fd8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=========================================\n",
      "Experiment Configured. We will test the following models: \n",
      "=========================================\n",
      "   - Neural Network\n",
      "   - Gradient Boosting Ensemble\n",
      "   - Support Vector Machine\n",
      "\n",
      "\n",
      "Iteration # 1  ======================================================||\n",
      "=================================================\n",
      "Beginning our experiment\n",
      "=================================================\n",
      "\n",
      "=========================================\n",
      "Compiling our models\n",
      "=========================================\n",
      "Compiling Neural Network\n",
      "Model Compiled!\n",
      "Compiling Gradient Boosting Ensemble\n",
      "Model Compiled!\n",
      "Compiling Support Vector Machine\n",
      "Model Compiled!\n",
      "\n",
      "=========================================\n",
      "Training our models\n",
      "=========================================\n",
      "Training Neural Network\n",
      "Training Gradient Boosting Ensemble\n",
      "Training Support Vector Machine\n",
      "\n",
      "Model Trained!\n",
      "Model Trained!\n",
      "Model Trained!\n",
      "=========================================\n",
      "Evaluating our models\n",
      "=========================================\n",
      "Evaluating Neural Network\n",
      "Evaluating Gradient Boosting Ensemble\n",
      "Evaluating Support Vector Machine\n",
      "\n",
      "Model Accuracy: 0.9\n",
      "Model Accuracy: 0.9\n",
      "Model Accuracy: 0.9\n",
      "Experiment Results:\n",
      "=========================================\n",
      "Models sorted by accuracy: \n",
      "Neural Network : 90.0 %.\n",
      "Gradient Boosting Ensemble : 90.0 %.\n",
      "Support Vector Machine : 90.0 %.\n",
      "=========================================\n",
      "Experiment complete\n",
      "=========================================\n"
     ]
    }
   ]
  }
 ]
}