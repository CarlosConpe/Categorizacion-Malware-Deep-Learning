from MachineLearningModel import *

# ! libraries that are required for this implementation
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
import time
import numpy as np
import pandas as pd 
import matplotlib.pyplot as plt 
# split X and y into training and testing sets
from sklearn.model_selection import train_test_split



# * This implements support vector machine classification and regression.
class SupportVectorMachine(MachineLearningModel):

    """
    Build classifier

    Parameters
    ----------
    regularization: Regularization parameter. The strength of the regularization is inversely 
    proportional to C. Must be strictly positive.
    kernel: Specifies the kernel type to be used in the algorithm.
    degree: Degree of the polynomial kernel function (poly). Ignored by all other kernels.
    gamma{scale, auto} : Kernel coefficient for rbf, poly and sigmoid.

    """
    # Constructor
    def __init__(self, regularization=1.0, kernel='rbf', degree=3, gamma='scale', name="Support Vector Machine", verbose="True"):
        super(SupportVectorMachine, self).__init__(model_name = name, verbose = verbose)
        self.regularization = regularization
        self.kernel = kernel
        self.degree = degree
        self.gamma = gamma

    # Method to build the support vector machine model
    def build(self):
        self.clf = SVC(C=self.regularization, kernel=self.kernel, degree=self.degree, gamma=self.gamma)

    # Method for compiling
    def compile(self):
        try:
            self.build()
            if self.verbose:
                print("Model Compiled!")
        except:
            print("Model wasn't compiled correctly!")

    # Method to process our data such that it is usable by our model
    def parse_data(self, dataset):
        super().parse_data()

    """
    Fit the SVM model according to the given training data.

    Parameters
    ----------
    training_data : {array-like, sparse matrix} of shape (n_samples, n_features) or (n_samples, n_samples)
        Training vectors, where `n_samples` is the number of samples and `n_features` is the number of features.
    training_labels : array-like of shape (n_samples,)
        Target values (class labels in classification).
    sample_weight : array-like of shape (n_samples,), default=None
        Per-sample weights. Rescale C per sample. Higher weights
        force the classifier to put more emphasis on these points.
    """
    def train(self, training_data, training_labels, sample_weight=None):
        # We grab the testing data so we can run our test
        start = time.time()
        try:
            self.clf.fit(X = training_data, y = training_labels,sample_weight=sample_weight)
            if self.verbose:
                print("Model Trained!")
            end = time.time()
            self.training_time= end - start
        except:
            print("Model wasn't trained correctly!")
            self.training_time = -1

    """
    Perform regression on samples in X.
    
    Parameters
    ----------
    samples : {array-like, sparse matrix} of shape (n_samples, n_features)
    """
    def evaluate(self, samples):
        # We grab the testing data so we can run our test
        start = time.time()
        try:
            sample_predictions = self.clf.predict(samples)
            self.precision = float(accuracy_score(samples, sample_predictions))
            if self.verbose:
                print('Model Accuracy: {0:0.4f}'.format(self.precision)) 
            end = time.time()
            self.evaluation_time = end - start
            self.mean_evaluation_time = end - start
            self.loss = 100.0 - self.precision
        except:
            print("Model Accuracy error: -1")
            self.precision = -1
            self.loss = -1
            self.evaluation_time = -1
            self.mean_evaluation_time = -1

    #Method to run the entire model. This is interface that would be used for any model. 
    def run_model(self, training_data , training_labels, samples):
        self.compile()
        self.train(training_data = training_data, training_labels=training_labels)
        self.evaluate(samples)

# ! Prueba con el dataset real (timpo aproximado de ejecuci√≥n, 10 min)

if __name__ == '__main__':
    data = '../../datasets/MalwareData.csv'
    df = pd.read_csv(filepath_or_buffer=data, sep="|")

    X = df.drop(['legitimate','Name','md5'], axis=1)
    y = df['legitimate']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

    # instantiate classifier with default hyperparameters
    svc = SupportVectorMachine(regularization=1.0, kernel='rbf', degree=3, gamma='scale', name="Support Vector Machine", verbose="True") 
    
    svc.run_model(training_data=X_train,training_labels=y_train, samples=X_test)