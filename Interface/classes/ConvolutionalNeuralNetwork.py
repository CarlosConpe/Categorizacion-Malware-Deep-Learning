from classes.MachineLearningModel import *
import tensorflow as tf
import time
import numpy as np


class ConvolutionalNeuralNetwork(MachineLearningModel):
    def build(self):
        layer_array = []
        # Input Layer
        layer_array.append(
            tf.keras.layers.Conv2D(
                28,
                (3, 3),
                activation="relu",
                input_shape=self.network_architecture["input_shape"],
            )
        )
        # layer_array.append(tf.keras.layers.MaxPooling2D((2, 2)))

        # Hidden Layers
        for layer in self.network_architecture["architecture"]:
            layer_array.append(tf.keras.layers.Conv2D(layer, (3, 3), activation="relu"))
            layer_array.append(tf.keras.layers.MaxPooling2D((2, 2)))

        # Output Layers
        layer_array.append(tf.keras.layers.Flatten())
        layer_array.append(tf.keras.layers.Dense(64, activation="relu"))
        layer_array.append(
            tf.keras.layers.Dense(self.network_architecture["output_size"])
        )

        # Our complete model
        self.model = tf.keras.Sequential(layer_array)

    def __init__(
        self,
        *,
        architecture,
        input_size,
        input_shape,
        output_size,
        epochs,
        name,
        verbose
    ):
        # We inherit from the machine learning model class:
        super(ConvolutionalNeuralNetwork, self).__init__(
            model_name=name, verbose=verbose
        )
        # We create a dictionary/hash map with the properties of our convolutional neural network
        self.network_architecture = {
            "architecture": architecture,
            "input_size": input_size,
            "input_shape": input_shape,
            "output_size": output_size,
            "epochs": epochs,
        }
        # We build our neural network based on the specifications
        self.build()

    # Compiling model with hard-coded metrics
    def compile(self):
        our_optimizer = "adam"
        our_metric = "accuracy"
        self.model.compile(
            optimizer=our_optimizer,
            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
            metrics=[our_metric],
        )

    # Train model
    def train(self, *, training_data, training_labels):
        start = time.time()
        self.model.fit(
            training_data, training_labels, epochs=self.network_architecture["epochs"]
        )
        end = time.time()
        self.training_time = end - start

    # Evaluate the accuracy of the model based on testing samples
    def evaluate(self, samples):
        # We grab the testing data so we can run our test

        start = time.time()

        testing_labels = samples["testing_labels"]
        testing_data = samples["testing_data"]

        # We build a probability model that will predict our testing data
        probability_model = tf.keras.Sequential([self.model, tf.keras.layers.Softmax()])
        predictions = probability_model.predict(testing_data)

        # We check how many correct guesses the neural network made
        correct_guesses = 0
        for i in range(0, len(testing_labels)):
            if testing_labels[i] == np.argmax(
                probability_model.predict(np.expand_dims(testing_data[i], 0), verbose=0)
            ):
                correct_guesses += 1
        self.accuracy = correct_guesses / len(testing_data)

        end = time.time()
        self.evaluation_time = end - start
